{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9b5270b",
   "metadata": {},
   "source": [
    "*Note: Place this notebook in STHN directory.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be96c211",
   "metadata": {},
   "source": [
    "# TGM (Satellite to Thermal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e3ef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install PyYAML transformers timm h5py torch torchvision faiss-cpu einops opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed123af",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ff5c63",
   "metadata": {},
   "source": [
    "[my_eval_pix2pix.py](./global_pipeline/my_eval_pix2pix.py)\n",
    "- [Input Image](./global_pipeline/my_eval_pix2pix.py:69)\n",
    "- [Output Image](./global_pipeline/my_eval_pix2pix.py:94)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e83058",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ./global_pipeline/my_eval_pix2pix.py --resume=\"js_models/TGM_nocontrast/best_model.pth\" --dataset_name=none --datasets_folder ./maps --G_net unet --GAN_upsample bilinear --GAN_resize 1024 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2730a305",
   "metadata": {},
   "source": [
    "## Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6f25a8",
   "metadata": {},
   "source": [
    "[my_TGM_folder2folder.py](./global_pipeline/my_TGM_folder2folder.py)\n",
    "- [Input Folder](./global_pipeline/my_TGM_folder2folder.py:296)\n",
    "- [Output Folder](./global_pipeline/my_TGM_folder2folder.py:297)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ecc6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "!py -3.13 ./global_pipeline/my_TGM_folder2folder.py --resume=\"js_models/TGM_nocontrast/best_model.pth\" --dataset_name=none --datasets_folder ./maps --G_net unet --GAN_upsample bilinear --GAN_resize 512 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab645e10",
   "metadata": {},
   "source": [
    "# SHN (Matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3142bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kornia scikit-image wandb openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f9a674",
   "metadata": {},
   "source": [
    "[my_myevaluate.py](./local_pipeline/my_myevaluate.py)\n",
    "- [Input Image](./local_pipeline/my_myevaluate.py:118)\n",
    "- [Output Image](./local_pipeline/my_myevaluate.py:119)\n",
    "- [Output Excel](./local_pipeline/my_myevaluate.py:168)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017a0073",
   "metadata": {},
   "source": [
    "## One-Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cc251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "print(\"cuda mem allocated:\", torch.cuda.memory_allocated() // (1024**2), \"MB\")\n",
    "print(\"cuda mem reserved:\",   torch.cuda.memory_reserved()   // (1024**2), \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dec6e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!py -3.13  ./local_pipeline/my_myevaluate.py --dataset_name none --eval_model js_models/1536_one_stage/STHN.pth --val_positive_dist_threshold 512 --lev0 --database_size 1536 --corr_level 4 --test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fc4231",
   "metadata": {},
   "source": [
    "## Two-Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd9d653",
   "metadata": {},
   "outputs": [],
   "source": [
    "!py -3.13  ./local_pipeline/my_myevaluate.py --dataset_name none --eval_model js_models/1536_two_stages/STHN.pth --val_positive_dist_threshold 512 --lev0 --database_size 1536 --corr_level 4 --test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8250e9d5",
   "metadata": {},
   "source": [
    "# TensorRT Conversion (STHN .pth → ONNX → TensorRT)\n",
    "- No `pycuda` is used (engine build via `trtexec`).\n",
    "- TensorRT `.engine` files are GPU/driver-specific: build them on the target machine (e.g., Jetson) with the same TensorRT version.\n",
    "- One-stage exports 1 ONNX/engine (coarse). Two-stage exports 2 ONNX/engines (coarse + fine). The crop/combine logic between stages remains in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da86be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd23a8f",
   "metadata": {},
   "source": [
    "## Export ONNX\n",
    "These commands export the weights from your `.pth` into ONNX files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f387e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m tools.export_sthn_onnx --pth \"js_models\\1536_one_stage\\STHN.pth\" --out_dir \"trt\\one_stage\" --stage coarse --resize_width 256 --corr_level 4 --iters 6 --database_size 1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec2d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!py -3.13 -m tools.export_sthn_onnx --pth \"js_models\\1536_two_stages\\STHN.pth\" --out_dir \"trt\\two_stages\" --stage both --resize_width 256 --corr_level 4 --iters 6  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834e0c0e",
   "metadata": {},
   "source": [
    "## Build TensorRT engines (requires TensorRT + `trtexec`)\n",
    "- Run these on the target GPU machine (e.g., Jetson).\n",
    "- If `trtexec` is not on your PATH, pass `--trtexec /full/path/to/trtexec`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f302449",
   "metadata": {},
   "source": [
    "### One-stage (coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ceecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m tools.build_tensorrt_engine --onnx \"trt/one_stage/sthn_coarse.onnx\" --engine \"trt/one_stage/sthn_coarse_fp16.engine\" --fp16 --trtexec /usr/src/tensorrt/bin/trtexec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b847e7e6",
   "metadata": {},
   "source": [
    "### Two-stage (coarse + fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adbc3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m tools.build_tensorrt_engine --onnx \"trt/two_stages/sthn_coarse.onnx\" --engine \"trt/two_stages/sthn_coarse_fp16.engine\" --fp16 --trtexec /usr/src/tensorrt/bin/trtexec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e898ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m tools.build_tensorrt_engine --onnx \"trt/two_stages/sthn_fine.onnx\" --engine \"trt/two_stages/sthn_fine_fp16.engine\" --fp16 --trtexec /usr/src/tensorrt/bin/trtexec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe0bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # One-stage (coarse)\n",
    "# !py -3.13 tools/build_tensorrt_engine.py --onnx trt/one_stage/sthn_coarse.onnx --engine trt/one_stage/sthn_coarse_fp16.engine --fp16 --shapes \"min=image1:1x3x256x256,image2:1x3x256x256;opt=image1:1x3x256x256,image2:1x3x256x256;max=image1:1x3x256x256,image2:1x3x256x256\"\n",
    "\n",
    "# # Two-stage (coarse + fine)\n",
    "# !py -3.13 tools/build_tensorrt_engine.py --onnx trt/two_stages/sthn_coarse.onnx --engine trt/two_stages/sthn_coarse_fp16.engine --fp16 --shapes \"min=image1:1x3x256x256,image2:1x3x256x256;opt=image1:1x3x256x256,image2:1x3x256x256;max=image1:1x3x256x256,image2:1x3x256x256\"\n",
    "# !py -3.13 tools/build_tensorrt_engine.py --onnx trt/two_stages/sthn_fine.onnx --engine trt/two_stages/sthn_fine_fp16.engine --fp16 --shapes \"min=image1_crop:1x3x256x256,image2:1x3x256x256;opt=image1_crop:1x3x256x256,image2:1x3x256x256;max=image1_crop:1x3x256x256,image2:1x3x256x256\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43be5c4",
   "metadata": {},
   "source": [
    "# TensorRT Inference (.engine)\n",
    "These use TensorRT engines directly (no `pycuda`).\n",
    "- One-stage: pass the coarse engine in `--eval_model`\n",
    "- Two-stage: pass both engines in `--eval_model` and `--eval_model_fine` and add `--two_stages`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb31f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-stage TensorRT inference (coarse engine only)\n",
    "!python3 ./local_pipeline/my_myevaluate_trt.py --dataset_name none --eval_model trt/one_stage/sthn_coarse.engine --val_positive_dist_threshold 512 --lev0 --database_size 1536 --corr_level 4 --test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3065c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-stage TensorRT inference (coarse + fine engines)\n",
    "!python3 ./local_pipeline/my_myevaluate_trt.py --dataset_name none --two_stages --eval_model trt/two_stages/sthn_coarse.engine --eval_model_fine trt/two_stages/sthn_fine.engine --val_positive_dist_threshold 512 --lev0 --database_size 1536 --corr_level 4 --test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
